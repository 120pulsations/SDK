.. _taskman:

-------------------
Task Management
-------------------

PxTask is a subsystem for managing compute resources for PhysX and APEX.
It manages CPU and GPU compute resources, as well as SPU units on 
PlayStation3, by distributing Tasks to a user-implemented dispatcher 
and resolving Task dependencies such that Tasks are run in a given order.

Middleware products typically do not want to create CPU threads for their 
own use.  This is especially true on consoles where execution threads 
can have significant overhead. In the PxTask model, the computational 
work is broken into jobs that are submitted to the game's thread pool as 
they become ready to run.

The following classes comprise the PxTask CPU resource management.

===================
TaskManager
===================

A TaskManager manages inter-task dependencies and dispatches ready tasks 
to their respective dispatcher. There is a dispatcher for CPU tasks, GPU 
tasks, and SPU tasks assigned to the TaskManager.

TaskManagers are owned and created by the SDK. Each PxScene will allocate 
its own TaskManager instance which users can configure with dispatchers 
through either the PxSceneDesc or directly through the TaskManager interface.

===================
CpuDispatcher
===================

The CpuDispatcher is an abstract class the SDK uses for interfacing with the 
application's thread pool. Typically, there will be one single 
CpuDispatcher for the entire application, since there is rarely a need
for more than one thread pool. A CpuDispatcher instance may be shared by 
more than one TaskManager, for example if multiple scenes are being used.

PxTask includes a default CpuDispatcher implementation, but we prefer 
applications to implement this class themselves so PhysX and APEX can 
efficiently share CPU resources with the application.

.. note::
	The TaskManager will call CpuDispatcher::submitTask() from either the 
	context of API calls (aka: scene::simulate()) or from other running 
	tasks, so the function must be thread-safe.
	
An implemention of the CpuDispatcher interface must call the following two methods on each submitted task for it to be run correctly::
	
        baseTask->run();	// optionally call runProfiled() to wrap with PVD profiling events
        baseTask->release();

The PxExtensions library has default implementations for all dispatcher types, the following code snippets are taken from SampleParticles and SampleBase and show how the default dispatchers are created. 
*mNbThreads* which is passed to *PxDefaultCpuDispatcherCreate* defines how many worker threads the CPU dispatcher will have. 

Best performance is usually achieved if the number of threads is equal to the available hardware threads of the platform you are running on::

        PxSceneDesc sceneDesc(mPhysics->getTolerancesScale());
        [...]
        // create CPU dispatcher which mNbThreads worker threads
        mCpuDispatcher = PxDefaultCpuDispatcherCreate(mNbThreads);
        if(!mCpuDispatcher)
            fatalError("PxDefaultCpuDispatcherCreate failed!");
        sceneDesc.cpuDispatcher	= mCpuDispatcher;
    #ifdef PX_WINDOWS
        // create GPU dispatcher
        pxTask::CudaContextManagerDesc cudaContextManagerDesc;
        mCudaContextManager = pxTask::createCudaContextManager(cudaContextManagerDesc);
        sceneDesc.gpuDispatcher = mCudaContextManager->getGpuDispatcher();
    #endif
        [...]   
        mScene = mPhysics->createScene(sceneDesc);
		
.. note::
	CudaContextManagerDesc support appGUID now. It only works on release build. If your application employs PhysX modules that use CUDA you need to use a GUID so that patches for 
	new architectures can be released for your game. You can obtain a GUID for your application from Nvidia. The application should log the failure into a file which can be 
	sent to NVIDIA for support. 

=======================================
CpuDispatcher Implementation Guidelines
=======================================

After the scene's TaskManager has found a ready-to-run task and submitted it to the 
appropriate dispatcher it is up to the dispatcher implementation to decide how and 
when the task will be run. 

Often in game scenarios the rigid body simulation is time critical and the goal is to
reduce the latency from simulate() to the completion of fetchResults(). The lowest
possible latency will be achieved when the PhysX tasks have exclusive access to CPU resources
during the update. In reality, PhysX will have to share compute resources with other game tasks. 
Below are some guidelines to help ensure a balance between throughput and latency when mixing
the PhysX update with other work.

- Avoid interleaving long running tasks with PhysX tasks, this will help reduce latency.

- Avoid assigning worker threads to the same execution core as higher priority threads. If a PhysX task is context switched during execution the rest of the rigid body pipeline may be stalled, increasing latency.

- PhysX occasionally submits tasks and then immediately waits for them to complete, because of this, executing tasks in LIFO (stack) order may perform better than FIFO (queue) order.

- PhysX is not a perfectly parallel SDK, so interleaving small to medium granularity tasks will generally result in higher overall throughput.

- If your thread pool has per-thread job-queues then queuing tasks on the thread they were submitted may result in more optimal CPU cache coherence, however this is not required. 


For more details see the default CpuDispatcher implementation that comes as part of the 
PxExtensions package. It uses worker threads that each have their own task queue and steal 
tasks from the back of other worker's queues (LIFO order) to improve workload distribution.
		
===================
BaseTask
===================

BaseTask is the abstract base class for all PxTask task types.  All task 
run() functions will be executed on application threads, so they 
need to be careful with their stack usage, use a little stack as 
possible, and they should never block for any reason.

===================
Task
===================

The Task class is the standard task type. Tasks must be submitted to the 
TaskManager each simulation step for them to be executed.  Tasks may be 
named at submission time, this allows them to be discoverable.  Tasks 
will be given a reference count of 1 when they are submitted, and the 
TaskManager::startSimulation() function decrements the reference count 
of all tasks and dispatches all Tasks whose reference count reaches zero.  
Before TaskManager::startSimulation() is called, Tasks can set 
dependencies on each other to control the order in which they are dispatched. 
Once simulation has started, it is still possible to submit new tasks and 
add dependencies, but it is up to the programmer to avoid race hazards. 
You cannot add dependencies to tasks that have already been dispatched, 
and newly submitted Tasks must have their reference count decremented 
before that Task will be allowed to execute.

Synchronization points can also be defined using Task names. The 
TaskManager will assign the name a TaskID with no Task implementation.  
When all of the named TaskID's dependencies are met, it will decrement 
the reference count of all Tasks with that name.

APEX uses the Task class almost exclusively to manage CPU 
resources. The ApexScene defines a number of named Tasks that the 
modules use to schedule their own Tasks (ex: start after LOD 
calculations are complete, finish before the PhysX scene is stepped).

===================
LightCpuTask
===================

LightCpuTask is another subclass of BaseTask that is explicitly 
scheduled by the programmer. LightCpuTasks have a reference count of 1 
when they are initialized, so their reference count must be decremented 
before they are dispatched. LightCpuTasks increment their continuation 
task reference count when they are initialized, and decrement the 
reference count when they are released (after completing their run() function)

PhysX 3.0 uses LightCpuTasks almost exclusively to manage CPU 
resources. For example, each stage of the simulation update may consist 
of multiple parallel tasks, when each of these tasks has finished execution 
it will decrement the reference count on the next task in the update chain. 
This will then be automatically dispatched for execution when its reference 
count reaches zero.

.. note::
	Even when using LightCpuTasks exclusively to manage CPU resources, the 
	TaskManager startSimulation() and stopSimulation() calls must be made 
	each simulation step to keep the GpuDispatcher synchronized.

The following code snippets show how the crabs' A.I. in SampleSubmarine is run as a CPU Task. By doing so the Crab A.I. is run as a background Task in parallel with the PhysX simulation update. 

For a CPU task that does not need handling of multiple continuations *LightCpuTask* can be subclassed. A *LightCpuTask* subclass requires that the getName and a run method be defined::

    class Crab: public ClassType, public physx::pxtask::LightCpuTask, public SampleAllocateable
    {
    public:
        Crab(SampleSubmarine& sample, const PxVec3& crabPos, RenderMaterial* material);
        ~Crab();
        [...]
        
        // Implements LightCpuTask
        virtual  const char*    getName() const { return "Crab AI Task"; }
        virtual  void           run();
        
        [...]   
    }

After PxScene::simulate() has been called, and the simulation started, the application calls removeReference() on each Crab task, this in turn causes it to be submitted to the CpuDispatcher for update. Note that it is also possible to submit tasks to the dispatcher directly (without manipulating reference counts) as follows::
    
	pxtask::LightCpuTask& task = &mCrab;
	mCpuDispatcher->submitTask(task);
    
Once queued for execution by the CpuDispatcher, one of the thread pool's worker threads will eventually call the task's run method. In this example the Crab task will perform raycasts against the scene and update its internal state machine::

    void Crab::run()
    {
        // run as a separate task/thread
        scanForObstacles();
        updateState();
    }

It is safe to perform API read calls, such as scene queries, from multiple threads while simulate() is running. However, care must be taken not to overlap API read and write calls from multiple threads. In this case the SDK will issue an error, see :ref:`dataaccess` for more information.
	
An example for explicit reference count modification and task dependency setup::

    // assume all tasks have a refcount of 1 and are submitted to the task manager
    // 3 task chains a0-a2, b0-b2, c0-c2
    // b0 shall start after a1
    // the a and c chain have no dependencies and shall run in parallel
    //
    // a0-a1-a2
    //      \
    //       b0-b1-b2
    // c0-c1-c2  
    
    // setup the 3 chains
    for(PxU32 i = 0; i < 2; i++)
    {
        a[i].setContinuation(&a[i+1]);
        b[i].setContinuation(&b[i+1]);
        c[i].setContinuation(&c[i+1]);
    }
    
    // b0 shall start after a1
    b[0].startAfter(a[1].getTaskID());
    
    // setup is done, now start all task by decrementing their refcount by 1
    // tasks with refcount == 0 will be submitted to the dispatcher (a0 & c0 will start).
    for(PxU32 i = 0; i < 3; i++)
    {
        a[i].removeReference();
        b[i].removeReference();
        c[i].removeReference();
    }